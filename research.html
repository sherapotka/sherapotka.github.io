<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Shera Potka — Ethical AI Research</title>
  <meta name="description" content="Shera Potka: research on fairness in recommenders, demographic bias in LLMs, and privacy‑preserving NLP." />
  <meta name="theme-color" content="#000000">
  <style>
    :root{
      --bg:#000000;            /* page background */
      --surface:#0d0d0d;       /* cards/nav */
      --elev:#141414;          /* subtle elevation */
      --border:#222;           /* hairline borders */
      --ink:#f5f5f5;           /* primary text */
      --muted:#b0b0b0;         /* secondary text */
      --accent:#ffffff;        /* links & accents */
      --ring:rgba(255,255,255,.16);
      --radius:18px;
      --shadow:0 14px 36px rgba(0,0,0,.65);
      --maxw:1000px;           /* tighter line length for readability */
    }

    *{box-sizing:border-box}
    html,body{margin:0;padding:0}

    body{
      background:var(--bg);
      color:var(--ink);
      font-family:ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial;
      line-height:1.65;
      font-size:17px; /* slightly larger for legibility */
      -webkit-font-smoothing:antialiased;
      text-rendering:optimizeLegibility;
    }

    .wrap{max-width:var(--maxw); margin:0 auto; padding:22px}

    /* Header */
    header{position:sticky; top:0; z-index:50; background:rgba(0,0,0,.8); border-bottom:1px solid var(--border); backdrop-filter:blur(8px)}
    .top{display:flex; align-items:center; justify-content:space-between; gap:16px; padding:12px 0}
    .brand{font-weight:800; letter-spacing:.2px}
    nav{display:flex; gap:10px; align-items:center}

    a{color:var(--accent); text-decoration:none}
    a:hover{text-decoration:underline}

    .chip{display:inline-flex; align-items:center; gap:8px; padding:8px 12px; border-radius:999px;
      background:transparent; color:var(--ink); border:1px solid var(--border)}

    .btn{display:inline-flex; align-items:center; gap:10px; padding:10px 14px; border-radius:12px;
      background:#0a0a0a; color:#fff; font-weight:700; border:1px solid #262626;
      box-shadow:0 6px 16px rgba(0,0,0,.5); transition:transform .12s, box-shadow .2s, background .15s}
    .btn:hover{transform:translateY(-1px); text-decoration:none; background:#131313; box-shadow:0 10px 24px rgba(0,0,0,.6)}
    .btn.ghost{background:transparent; color:var(--ink); border:1px solid var(--border); box-shadow:none}
    .btn.sm{padding:8px 12px; font-weight:600}
    .btn.block{width:100%; justify-content:center}

    .card{background:var(--surface); border:1px solid var(--border); border-radius:var(--radius); padding:20px; box-shadow:var(--shadow)}

    /* Hero */
    .hero{padding:24px 0 8px; display:grid; grid-template-columns:1.2fr .8fr; gap:22px}
    .eyebrow{display:inline-flex; align-items:center; gap:8px; color:var(--muted)}
    .eyebrow::before{content:""; width:8px; height:8px; border-radius:999px; background:var(--accent)}
    h1{font-size:clamp(30px,3.6vw,42px); line-height:1.15; margin:.25rem 0}
    .tagline{font-size:1.02rem; color:var(--muted); max-width:70ch}

    /* Sections */
    .section{margin:38px 0 18px}
    .section h2{font-size:1.35rem; margin:.15rem 0 8px}
    .lead{font-size:1.02rem}
    .muted{color:var(--muted)}
    .small{font-size:.92rem}

    /* Contribution blocks */
    .contrib{display:grid; grid-template-columns:1.25fr .75fr; gap:18px; align-items:start}
    .bullets{margin:10px 0 0 0; padding-left:18px}
    .bullets li{margin:6px 0}

    /* Media */
    .media{display:flex; align-items:flex-start; justify-content:center}
    .frame{margin:0; padding:10px; background:var(--elev); border:1px solid var(--border); border-radius:14px;
      display:flex; flex-direction:column; align-items:center; width:100%}
    .frame img{display:block; width:100%; height:auto; max-height:460px; object-fit:contain; border-radius:10px; cursor:zoom-in; transition:transform .2s}
    .frame img:hover{transform:translateY(-2px)}
    .frame figcaption{margin-top:8px; color:var(--muted); font-size:.9rem; text-align:center}

    /* Toolkit chips */
    .chips{display:flex; flex-wrap:wrap; gap:10px}
    .chip.soft{background:transparent; border-color:var(--border); color:#d2d2d2}

    /* Future grid */
    .future{display:grid; grid-template-columns:repeat(2,1fr); gap:16px}
    .future .fcard{padding:16px}
    .fcard h3{margin:6px 0 8px; font-size:1.02rem}

    /* Publications */
    .pubs{list-style:none; padding-left:0; margin:0; display:grid; gap:10px}
    .pub .meta{color:var(--muted); margin-top:4px}

    footer{margin:40px 0 18px; color:var(--muted)}

    /* Responsive */
    @media (max-width:980px){
      :root{--maxw:720px}
      body{font-size:16.5px}
      .hero{grid-template-columns:1fr; gap:18px}
      .contrib{grid-template-columns:1fr}
      .future{grid-template-columns:1fr}
      header{position:static; background:var(--bg); backdrop-filter:none}
    }

    /* Accessibility */
    :where(a,button,[role="button"],.btn,.chip):focus-visible{outline:2px dashed var(--accent); outline-offset:3px}
    @media (prefers-reduced-motion:reduce){*{transition:none!important}}
  </style>
</head>
<body>
  <header>
    <div class="wrap top">
      <div class="brand">Shera Potka</div>
      <nav aria-label="Primary">
        <a class="chip" href="/">← Main site</a>
        <a class="btn ghost" href="SheraPotkaCVa.pdf" target="_blank" rel="noopener">CV</a>
        <a class="btn" href="ResearchStatmentShera.pdf" download title="Download Shera's Research Statement">Download Research Statement</a>
      </nav>
    </div>
  </header>

  <main class="wrap" id="main">
    <!-- HERO -->
    <section class="hero card" aria-labelledby="hero-title">
      <div>
        <span class="eyebrow">Research Statement</span>
        <h1 id="hero-title">Ethical AI Systems</h1>
        <p class="tagline">Technically robust, ethically grounded, and socially responsible AI. Focus areas: fairness in recommenders, demographic bias in LLMs, and privacy‑preserving NLP.</p>
        <p>My work integrates algorithmic innovation with critical reflection on social impacts, ensuring models optimize performance while upholding equity, transparency, and accountability. Combining computational experiments with insights from computer science and the social sciences, I address the dual challenge of <em>robustness</em> and <em>trustworthiness</em>. The goal: mitigate systemic harms while preserving utility for responsible, real‑world deployment.</p>
        <div style="display:flex; gap:10px; flex-wrap:wrap; margin-top:12px">
          <a class="btn" href="ResearchStatmentShera.pdf" download>Download Statement</a>
          <a class="btn ghost" href="#publications">Jump to Publications</a>
        </div>
      </div>
      <aside class="card" aria-label="Highlights">
        <div class="muted small" style="margin-bottom:8px">Highlights</div>
        <ul class="bullets" style="margin:0">
          <li><strong>FairRec / MinWalk:</strong> Fairness‑aware link recommendation improving long‑term minority visibility without significant precision loss.</li>
          <li><strong>Bias Auditing:</strong> Large‑scale audits across OpenAI/Google/Microsoft/Cohere/BGE using <em>Fightin’ Words</em>, <em>SC‑WEAT</em>, clustering, and divergence measures.</li>
          <li><strong>Weighted Bias Scoring:</strong> Framework inspired by LLMBI capturing nuanced demographic disparities.</li>
          <li><strong>Differential Privacy:</strong> CluSanT and embedding‑level perturbations balancing privacy guarantees with semantic coherence.</li>
          <li><strong>Cross‑Domain:</strong> Methods span NLP and recommenders; ready for compliance contexts (EU AI Act, NIST RMF).</li>
        </ul>
      </aside>
    </section>

    <!-- CONTRIBUTION 1 -->
    <section class="section" aria-labelledby="fairness">
      <h2 id="fairness">1) Fairness in Recommendation Systems</h2>
      <div class="contrib">
        <div class="card">
          <p class="lead">Recommendation algorithms shape visibility. <strong>FairRec/MinWalk</strong> optimizes both accuracy and equitable exposure by integrating exposure‑parity constraints and dynamic network modeling.</p>
          <ul class="bullets">
            <li>Mitigates homophily & popularity bias; boosts minority visibility over time.</li>
            <li>Constrained optimization + stochastic sampling scales to large graphs.</li>
            <li>On social/citation graphs: visibility gains for under‑represented users with minimal precision impact.</li>
          </ul>
        </div>
        <div class="card media">
          <figure class="frame">
            <img src="Fairrec.png" alt="Visibility improvements for minority nodes over 30 iterations" loading="lazy" decoding="async" data-full="Fairrec.png">
            <figcaption>Minority visibility over training iterations</figcaption>
            <div class="actions" style="margin-top:10px">
              <a class="btn sm" href="https://www.researchgate.net/publication/393752947_Enhancing_Structural_Minority_Visibility_in_Link_Recommendations" target="_blank" rel="noopener">Paper</a>
            </div>
          </figure>
        </div>
      </div>
    </section>

    <!-- CONTRIBUTION 2 -->
    <section class="section" aria-labelledby="bias">
      <h2 id="bias">2) Demographic Bias Detection in Large Language Models</h2>
      <div class="contrib">
        <div class="card">
          <p class="lead">I quantify and explain demographic biases in embeddings from major providers using frequency‑weighted <em>Fightin’ Words</em>, <em>SC‑WEAT</em>, clustering, and divergence tests.</p>
          <ul class="bullets">
            <li>Interpretable scores reveal persistent gender/race associations that surface in downstream tasks (e.g., product recommendations).</li>
            <li>Multi‑method audit pipelines (Marked Words, SVM, Jensen–Shannon divergence) support actionable mitigations.</li>
            <li>Outputs inform debiasing strategies for production LLMs.</li>
          </ul>
        </div>
        <div class="card media">
          <figure class="frame">
            <img src="Bias.png" alt="Gender association of top words across models" loading="lazy" decoding="async" data-full="Bias.png">
            <figcaption>Gender‑linked associations across embeddings</figcaption>
            <div class="actions" style="margin-top:10px">
              <a class="btn sm" href="https://link.springer.com/content/pdf/10.1007/978-981-96-6294-4_20.pdf" target="_blank" rel="noopener">Paper</a>
            </div>
          </figure>
        </div>
      </div>
    </section>

    <!-- CONTRIBUTION 3 -->
    <section class="section" aria-labelledby="privacy">
      <h2 id="privacy">3) Privacy‑Preserving Text Generation</h2>
      <div class="contrib">
        <div class="card">
          <p class="lead">I develop differentially private generation by perturbing <em>embedding space</em> rather than token probabilities, preserving coherence while reducing memorization and leakage.</p>
          <ul class="bullets">
            <li>DP‑SGD + inference‑time embedding noise produce smooth, contextual outputs.</li>
            <li>Lower identifiable memorization with high human‑rated quality retained.</li>
            <li>Applications: healthcare narratives, legal anonymization, educational feedback.</li>
          </ul>
        </div>
        <div class="card media">
          <figure class="frame">
            <img src="privat.png" alt="Privacy–utility frontier comparing methods" loading="lazy" decoding="async" data-full="privat.png">
            <figcaption>Privacy–utility frontier</figcaption>
            <div class="actions" style="margin-top:10px">
              <a class="btn sm" href="https://aclanthology.org/2025.naacl-long.187/" target="_blank" rel="noopener">Paper</a>
            </div>
          </figure>
        </div>
      </div>
    </section>

    <!-- FIVE-YEAR PLAN -->
    <section class="section" aria-labelledby="plan">
      <h2 id="plan">Five‑Year Plan (at a glance)</h2>
      <div class="card">
        <ul class="bullets">
          <li><strong>Dynamic Fairness:</strong> Treat fairness as a temporal property in evolving networks; sustain minority visibility at scale.</li>
          <li><strong>Systemic Bias:</strong> Move beyond local prompts to structural rebalancing of embedding spaces.</li>
          <li><strong>Privacy as Transformation:</strong> Coherence‑preserving, embedding‑level privacy integrated into generation loops.</li>
          <li><strong>Ethical Embeddings Theory:</strong> Unified mathematical framework connecting visibility, stereotypes, and attribute leakage.</li>
        </ul>
        <p class="muted small">Details elaborated in the downloadable statement.</p>
      </div>
    </section>

    <!-- METHODS -->
    <section class="section" aria-labelledby="toolkit">
      <h2 id="toolkit">Methodological Toolkit</h2>
      <div class="card">
        <div class="chips" style="margin-bottom:8px">
          <span class="chip soft">Embedding analysis (PCA, cosine)</span>
          <span class="chip soft">Directional tests & SC‑WEAT</span>
          <span class="chip soft">Exposure & demographic parity</span>
          <span class="chip soft">Disparity ratios & equal opportunity</span>
          <span class="chip soft">Custom losses; Lagrangian relaxation</span>
          <span class="chip soft">DP‑SGD; embedding perturbation</span>
          <span class="chip soft">BLEU · ROUGE · perplexity · CoLA</span>
          <span class="chip soft">BERT · RoBERTa · GPT · Cohere · BGE</span>
        </div>
        <p class="muted small">A diverse, reproducible toolkit for rigorous, cross‑domain research.</p>
      </div>
    </section>

    <!-- PUBLICATIONS -->
    <section id="publications" class="section" aria-labelledby="pubs-heading">
      <h2 id="pubs-heading">Selected Publications</h2>
      <ul class="pubs" itemscope itemtype="https://schema.org/ItemList">
        <meta itemprop="name" content="Selected Publications by Shera Potka"/>
        <li class="pub card" itemprop="itemListElement" itemscope itemtype="https://schema.org/ScholarlyArticle">
          <span class="title" itemprop="name">Community Structure and Coherence in Digital Humanities Works</span>
          <div class="meta"><span class="venue" itemprop="isPartOf">IISA 2023</span> — <em>Best Paper Award</em></div>
          <div class="links"><a class="btn sm ghost" href="https://ieeexplore.ieee.org/document/10345939" target="_blank" rel="noopener" itemprop="url">PDF</a></div>
        </li>
        <li class="pub card" itemprop="itemListElement" itemscope itemtype="https://schema.org/ScholarlyArticle">
          <span class="title" itemprop="name">Enhancing Structural Minority Visibility in Link Recommendations (MinWalk)</span>
          <div class="meta"><span class="venue" itemprop="isPartOf">MEDES 2024</span> — <em>Best Paper Award</em></div>
          <div class="links"><a class="btn sm ghost" href="https://www.researchgate.net/publication/393752947_Enhancing_Structural_Minority_Visibility_in_Link_Recommendations" target="_blank" rel="noopener" itemprop="url">PDF</a></div>
        </li>
        <li class="pub card" itemprop="itemListElement" itemscope itemtype="https://schema.org/ScholarlyArticle">
          <span class="title" itemprop="name">Word Embedding Bias in Large Language Models</span>
          <div class="meta"><span class="venue" itemprop="isPartOf">I‑SPAN 2025</span></div>
          <div class="links"><a class="btn sm ghost" href="https://link.springer.com/content/pdf/10.1007/978-981-96-6294-4_20.pdf" target="_blank" rel="noopener" itemprop="url">PDF</a></div>
        </li>
        <li class="pub card" itemprop="itemListElement" itemscope itemtype="https://schema.org/ScholarlyArticle">
          <span class="title" itemprop="name">Gender & Race Bias in Consumer Product Recommendations</span>
          <div class="meta"><span class="venue" itemprop="isPartOf">AINA 2025</span></div>
          <div class="links"><a class="btn sm ghost" href="https://www.researchgate.net/publication/390751836_Gender_and_Race_Bias_in_Consumer_Product_Recommendations_by_Large_Language_Models" target="_blank" rel="noopener" itemprop="url">PDF</a></div>
        </li>
        <li class="pub card" itemprop="itemListElement" itemscope itemtype="https://schema.org/ScholarlyArticle">
          <span class="title" itemprop="name">CluSanT: Differentially Private and Semantically Coherent Text Sanitization</span>
          <div class="meta"><span class="venue" itemprop="isPartOf">NAACL 2025</span></div>
          <div class="links"><a class="btn sm ghost" href="https://aclanthology.org/2025.naacl-long.187/" target="_blank" rel="noopener" itemprop="url">PDF</a></div>
        </li>
      </ul>
    </section>

    <footer>
      <div class="muted small">© <span id="year"></span> Shera Potka · <a href="/">Home</a></div>
    </footer>
  </main>

  <!-- Lightbox -->
  <dialog id="lightbox" aria-label="Image preview">
    <img class="lightbox-img" src="" alt="">
    <div style="display:flex; justify-content:space-between; gap:12px; margin:10px auto 0; width:min(92vw,1100px)">
      <button class="btn ghost" id="closeBox" aria-label="Close image">Close</button>
      <span class="muted small">Click outside or press Esc to dismiss</span>
    </div>
  </dialog>

  <script>
    document.getElementById('year').textContent = new Date().getFullYear();

    // Lightbox
    const dlg = document.getElementById('lightbox');
    const imgEl = dlg.querySelector('.lightbox-img');
    const closeBtn = document.getElementById('closeBox');
    document.querySelectorAll('.media img').forEach(img=>{
      img.addEventListener('click', ()=>{
        imgEl.src = img.dataset.full || img.src;
        imgEl.alt = img.alt || "";
        if (!dlg.open) dlg.showModal();
      });
    });
    closeBtn.addEventListener('click', ()=> dlg.close());
    dlg.addEventListener('click', (e)=>{
      const rect = imgEl.getBoundingClientRect();
      const inImage = e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.top  && e.clientY <= rect.bottom;
      if (!inImage) dlg.close();
    });
  </script>
</body>
</html>
